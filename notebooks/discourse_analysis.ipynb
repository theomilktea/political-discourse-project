{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38660622-edfe-4b10-8d4c-db22bdcb5c64",
   "metadata": {},
   "source": [
    "Political Discourse Keyword Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d348871-0890-408f-a29e-12e2d167d623",
   "metadata": {},
   "source": [
    "This notebook will explore word usage patterns across 20 speeches made by current Secretary General Ant√≥nio Guterres using basic NLP and text analysis techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da05b93d-6e00-4362-a939-dec2f4eb5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c88f3c0-98bb-47af-a4fd-a7d5b067499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/raw/\"\n",
    "files = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b9e3a5-2fa6-4f11-8b2d-91b6cb8a6240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 speeches\n"
     ]
    }
   ],
   "source": [
    "speeches = []\n",
    "for file in sorted(os.listdir(data_path)):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(data_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            speeches.append(text)\n",
    "\n",
    "print(f\"Loaded {len(speeches)} speeches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589ba346-32b0-43df-9a28-dc7e31a19e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we enter the new year, the world stands at a crossroads.\n",
      "\n",
      "\n",
      "Chaos and uncertainty surround us. \n",
      "\n",
      "\n",
      "Division. Violence. Climate breakdown. And systemic violations of international law.\n",
      "\n",
      "\n",
      "A retreat from the very principles that bind us together as a human family. \n",
      "\n",
      "\n",
      "People everywhere are asking: Are leaders even listening? Are they ready to act.\n",
      "\n",
      "\n",
      "As we turn the page on a turbulent year, one fact s\n"
     ]
    }
   ],
   "source": [
    "print(speeches[0][:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b824ec02-3530-4b7c-aeb9-8da75e8dbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb00cbb-7b6c-40a1-b873-cf1a789cc8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as we enter the new year the world stands at a crossroads\n",
      "\n",
      "\n",
      "chaos and uncertainty surround us \n",
      "\n",
      "\n",
      "division violence climate breakdown and systemic violations of international law\n",
      "\n",
      "\n",
      "a retreat from the very principles that bind us together as a human family \n",
      "\n",
      "\n",
      "people everywhere are asking are leaders e\n"
     ]
    }
   ],
   "source": [
    "cleaned_speeches = []\n",
    "for speech in speeches:\n",
    "    text = speech.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    cleaned_speeches.append(text)\n",
    "\n",
    "print(cleaned_speeches[0][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5324499-79cd-4922-a401-8dc9486c4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 6403\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "all_tokens = []\n",
    "for speech in cleaned_speeches:\n",
    "    doc = nlp(speech)\n",
    "    tokens = [token.text for token in doc if token.is_alpha]\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "print(f\"Total number of words: {len(all_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2866c72c-533a-4d3d-940f-1fe06b7a2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 349),\n",
       " ('and', 340),\n",
       " ('of', 222),\n",
       " ('to', 217),\n",
       " ('a', 108),\n",
       " ('in', 91),\n",
       " ('is', 78),\n",
       " ('for', 75),\n",
       " ('we', 70),\n",
       " ('that', 68),\n",
       " ('are', 57),\n",
       " ('this', 53),\n",
       " ('on', 48),\n",
       " ('i', 47),\n",
       " ('it', 46),\n",
       " ('as', 44),\n",
       " ('more', 43),\n",
       " ('all', 37),\n",
       " ('with', 35),\n",
       " ('people', 31)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269e503-94e1-4653-be96-7709cb7b5f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
